{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281bb6e9-ae3b-424f-890e-39a439bd90b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ab7abe-32a7-4314-a51c-6ed6a51f9f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subcat</th>\n",
       "      <th>author</th>\n",
       "      <th>era</th>\n",
       "      <th>origin</th>\n",
       "      <th>originid</th>\n",
       "      <th>simptrad</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>周易(正文)</td>\n",
       "      <td>經</td>\n",
       "      <td>易類</td>\n",
       "      <td>NaN</td>\n",
       "      <td>周</td>\n",
       "      <td>kanseki</td>\n",
       "      <td>KR1a0001</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>子夏易傳</td>\n",
       "      <td>經</td>\n",
       "      <td>易類</td>\n",
       "      <td>卜商</td>\n",
       "      <td>周</td>\n",
       "      <td>kanseki</td>\n",
       "      <td>KR1a0002</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>周易鄭康成註</td>\n",
       "      <td>經</td>\n",
       "      <td>易類</td>\n",
       "      <td>鄭玄</td>\n",
       "      <td>汉</td>\n",
       "      <td>kanseki</td>\n",
       "      <td>KR1a0003</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>增補鄭氏周易</td>\n",
       "      <td>經</td>\n",
       "      <td>易類</td>\n",
       "      <td>鄭玄</td>\n",
       "      <td>汉</td>\n",
       "      <td>kanseki</td>\n",
       "      <td>KR1a0004</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>陸氏易解</td>\n",
       "      <td>經</td>\n",
       "      <td>易類</td>\n",
       "      <td>陸績</td>\n",
       "      <td>吴</td>\n",
       "      <td>kanseki</td>\n",
       "      <td>KR1a0005</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32474</th>\n",
       "      <td>46027</td>\n",
       "      <td>竹齋集</td>\n",
       "      <td>集</td>\n",
       "      <td>別集類</td>\n",
       "      <td>王冕</td>\n",
       "      <td>明</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>7220_ZHU ZHAI JI (BAMBOO HOUSE)</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32475</th>\n",
       "      <td>46028</td>\n",
       "      <td>莊子的故事</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>宋曄</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>23913_ZHUANG-ZI'S STORY</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32476</th>\n",
       "      <td>46029</td>\n",
       "      <td>駐春園小史</td>\n",
       "      <td>集</td>\n",
       "      <td>小说</td>\n",
       "      <td>吳航野客</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>27328_ZHUCHUNYUAN XIAOSHI</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32477</th>\n",
       "      <td>46030</td>\n",
       "      <td>左傳</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>左丘明</td>\n",
       "      <td>春秋</td>\n",
       "      <td>gutenberg</td>\n",
       "      <td>24136_ZUO ZHUAN</td>\n",
       "      <td>trad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32478</th>\n",
       "      <td>46031</td>\n",
       "      <td>世说新语</td>\n",
       "      <td>NaN</td>\n",
       "      <td>筆記小说</td>\n",
       "      <td>刘义庆</td>\n",
       "      <td>南北朝</td>\n",
       "      <td>ctext</td>\n",
       "      <td>NaN</td>\n",
       "      <td>simp</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32479 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   title genre subcat author  era     origin  \\\n",
       "0          0  周易(正文)     經     易類    NaN    周    kanseki   \n",
       "1          1    子夏易傳     經     易類     卜商    周    kanseki   \n",
       "2          2  周易鄭康成註     經     易類     鄭玄    汉    kanseki   \n",
       "3          3  增補鄭氏周易     經     易類     鄭玄    汉    kanseki   \n",
       "4          4    陸氏易解     經     易類     陸績    吴    kanseki   \n",
       "...      ...     ...   ...    ...    ...  ...        ...   \n",
       "32474  46027     竹齋集     集    別集類     王冕    明  gutenberg   \n",
       "32475  46028   莊子的故事   NaN    NaN     宋曄  NaN  gutenberg   \n",
       "32476  46029   駐春園小史     集     小说   吳航野客  NaN  gutenberg   \n",
       "32477  46030      左傳   NaN    NaN    左丘明   春秋  gutenberg   \n",
       "32478  46031    世说新语   NaN   筆記小说    刘义庆  南北朝      ctext   \n",
       "\n",
       "                              originid simptrad notes  \n",
       "0                             KR1a0001     trad   NaN  \n",
       "1                             KR1a0002     trad   NaN  \n",
       "2                             KR1a0003     trad   NaN  \n",
       "3                             KR1a0004     trad   NaN  \n",
       "4                             KR1a0005     trad   NaN  \n",
       "...                                ...      ...   ...  \n",
       "32474  7220_ZHU ZHAI JI (BAMBOO HOUSE)     trad   NaN  \n",
       "32475          23913_ZHUANG-ZI'S STORY     trad   NaN  \n",
       "32476        27328_ZHUCHUNYUAN XIAOSHI     trad   NaN  \n",
       "32477                  24136_ZUO ZHUAN     trad   NaN  \n",
       "32478                              NaN     simp   NaN  \n",
       "\n",
       "[32479 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('/Users/lola/Manning_DATA490/corpus_metadata.tsv', sep='\\t') #reading in corpus into a data frame\n",
    "corpus = corpus.iloc[:, :10]\n",
    "corpus['id'] = corpus['id'].astype(str)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98bf396-b111-4bf0-bbd2-e6adbd58edb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REMOVE = [\n",
    "    \"』\",\n",
    "    \"。\",\n",
    "    \"！\",\n",
    "    \"，\",\n",
    "    \"：\",\n",
    "    \"、\",\n",
    "    \"（\",\n",
    "    \"）\",\n",
    "    \"；\",\n",
    "    \"？\",\n",
    "    \"〉\",\n",
    "    \"〈\",\n",
    "    \"」\",\n",
    "    \"「\",\n",
    "    \"『\",\n",
    "    \"“\",\n",
    "    \"”\",\n",
    "    \"!\",\n",
    "    '\"',\n",
    "    \"#\",\n",
    "    \"$\",\n",
    "    \"%\",\n",
    "    \"&\",\n",
    "    \"'\",\n",
    "    \"(\",\n",
    "    \")\",\n",
    "    \"*\",\n",
    "    \"+\",\n",
    "    \",\",\n",
    "    \"-\",\n",
    "    \".\",\n",
    "    \"/\",\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "    \":\",\n",
    "    \";\",\n",
    "    \"<\",\n",
    "    \"=\",\n",
    "    \">\",\n",
    "    \"?\",\n",
    "    \"@\",\n",
    "    \"[\",\n",
    "    \"\\\\\",\n",
    "    \"]\",\n",
    "    \"_\",\n",
    "    \"`\",\n",
    "    \"{\",\n",
    "    \"|\",\n",
    "    \"}\",\n",
    "    \"~\",\n",
    "    \"¤\",\n",
    "    \"±\",\n",
    "    \"·\",\n",
    "    \"×\",\n",
    "    \"à\",\n",
    "    \"á\",\n",
    "    \"è\",\n",
    "    \"é\",\n",
    "    \"ê\",\n",
    "    \"ì\",\n",
    "    \"í\",\n",
    "    \"ò\",\n",
    "    \"ó\",\n",
    "    \"÷\",\n",
    "    \"ù\",\n",
    "    \"ú\",\n",
    "    \"ü\",\n",
    "    \"ā\",\n",
    "    \"ī\",\n",
    "    \"ń\",\n",
    "    \"ň\",\n",
    "    \"ō\",\n",
    "    \"ū\",\n",
    "    \"ǎ\",\n",
    "    \"ǐ\",\n",
    "    \"ǔ\",\n",
    "    \"ǖ\",\n",
    "    \"ǘ\",\n",
    "    \"ǚ\",\n",
    "    \"ǜ\",\n",
    "    \"ǹ\",\n",
    "    \"ɑ\",\n",
    "    \"ɡ\",\n",
    "    \"α\",\n",
    "    \"β\",\n",
    "    \"γ\",\n",
    "    \"ε\",\n",
    "    \"ζ\",\n",
    "    \"η\",\n",
    "    \"θ\",\n",
    "    \"ι\",\n",
    "    \"κ\",\n",
    "    \"λ\",\n",
    "    \"μ\",\n",
    "    \"ν\",\n",
    "    \"ξ\",\n",
    "    \"ο\",\n",
    "    \"π\",\n",
    "    \"ρ\",\n",
    "    \"σ\",\n",
    "    \"τ\",\n",
    "    \"υ\",\n",
    "    \"φ\",\n",
    "    \"χ\",\n",
    "    \"ψ\",\n",
    "    \"ω\",\n",
    "    \"а\",\n",
    "    \"б\",\n",
    "    \"в\",\n",
    "    \"г\",\n",
    "    \"д\",\n",
    "    \"е\",\n",
    "    \"к\",\n",
    "    \"о\",\n",
    "    \"п\",\n",
    "    \"р\",\n",
    "    \"с\",\n",
    "    \"т\",\n",
    "    \"у\",\n",
    "    \"ф\",\n",
    "    \"х\",\n",
    "    \"ц\",\n",
    "    \"ч\",\n",
    "    \"ш\",\n",
    "    \"щ\",\n",
    "    \"ъ\",\n",
    "    \"ы\",\n",
    "    \"ь\",\n",
    "    \"э\",\n",
    "    \"ю\",\n",
    "    \"я\",\n",
    "    \"ё\",\n",
    "    \"—\",\n",
    "    \"‖\",\n",
    "    \"‘\",\n",
    "    \"’\",\n",
    "    \"…\",\n",
    "    \"※\",\n",
    "    \"ⅰ\",\n",
    "    \"ⅲ\",\n",
    "    \"∈\",\n",
    "    \"∏\",\n",
    "    \"∑\",\n",
    "    \"√\",\n",
    "    \"∠\",\n",
    "    \"∥\",\n",
    "    \"∧\",\n",
    "    \"∩\",\n",
    "    \"∪\",\n",
    "    \"∫\",\n",
    "    \"∮\",\n",
    "    \"∶\",\n",
    "    \"∷\",\n",
    "    \"∽\",\n",
    "    \"≈\",\n",
    "    \"≌\",\n",
    "    \"≡\",\n",
    "    \"⊙\",\n",
    "    \"⊥\",\n",
    "    \"⌒\",\n",
    "    \"①\",\n",
    "    \"②\",\n",
    "    \"③\",\n",
    "    \"④\",\n",
    "    \"⑤\",\n",
    "    \"⑥\",\n",
    "    \"⑦\",\n",
    "    \"⑧\",\n",
    "    \"⑨\",\n",
    "    \"⑩\",\n",
    "    \"⑴\",\n",
    "    \"⑵\",\n",
    "    \"⑶\",\n",
    "    \"⑷\",\n",
    "    \"⑸\",\n",
    "    \"⑹\",\n",
    "    \"⑺\",\n",
    "    \"⑻\",\n",
    "    \"⑼\",\n",
    "    \"⑽\",\n",
    "    \"⑾\",\n",
    "    \"⑿\",\n",
    "    \"⒀\",\n",
    "    \"⒁\",\n",
    "    \"⒂\",\n",
    "    \"⒃\",\n",
    "    \"⒄\",\n",
    "    \"⒅\",\n",
    "    \"⒆\",\n",
    "    \"⒈\",\n",
    "    \"⒉\",\n",
    "    \"⒊\",\n",
    "    \"⒋\",\n",
    "    \"⒌\",\n",
    "    \"⒍\",\n",
    "    \"⒎\",\n",
    "    \"⒏\",\n",
    "    \"⒐\",\n",
    "    \"⒑\",\n",
    "    \"⒒\",\n",
    "    \"⒓\",\n",
    "    \"⒔\",\n",
    "    \"⒕\",\n",
    "    \"⒖\",\n",
    "    \"⒗\",\n",
    "    \"⒘\",\n",
    "    \"⒙\",\n",
    "    \"⒚\",\n",
    "    \"⒛\",\n",
    "    \"─\",\n",
    "    \"┅\",\n",
    "    \"┋\",\n",
    "    \"┌\",\n",
    "    \"┍\",\n",
    "    \"┎\",\n",
    "    \"┏\",\n",
    "    \"┐\",\n",
    "    \"┑\",\n",
    "    \"┒\",\n",
    "    \"┓\",\n",
    "    \"└\",\n",
    "    \"┕\",\n",
    "    \"┘\",\n",
    "    \"┙\",\n",
    "    \"┚\",\n",
    "    \"┛\",\n",
    "    \"├\",\n",
    "    \"┝\",\n",
    "    \"┞\",\n",
    "    \"┠\",\n",
    "    \"┡\",\n",
    "    \"┢\",\n",
    "    \"┣\",\n",
    "    \"┤\",\n",
    "    \"┥\",\n",
    "    \"┦\",\n",
    "    \"┧\",\n",
    "    \"┩\",\n",
    "    \"┪\",\n",
    "    \"┫\",\n",
    "    \"┬\",\n",
    "    \"┭\",\n",
    "    \"┮\",\n",
    "    \"┯\",\n",
    "    \"┰\",\n",
    "    \"┱\",\n",
    "    \"┲\",\n",
    "    \"┳\",\n",
    "    \"■\",\n",
    "    \"□\",\n",
    "    \"▲\",\n",
    "    \"△\",\n",
    "    \"◆\",\n",
    "    \"◇\",\n",
    "    \"○\",\n",
    "    \"◎\",\n",
    "    \"●\",\n",
    "    \"★\",\n",
    "    \"︶\",\n",
    "    \"﹑\",\n",
    "    \"﹔\",\n",
    "    \"﹖\",\n",
    "    \"＂\",\n",
    "    \"＃\",\n",
    "    \"％\",\n",
    "    \"＆\",\n",
    "    \"＊\",\n",
    "    \"．\",\n",
    "    \"／\",\n",
    "    \"０\",\n",
    "    \"１\",\n",
    "    \"２\",\n",
    "    \"３\",\n",
    "    \"４\",\n",
    "    \"５\",\n",
    "    \"６\",\n",
    "    \"７\",\n",
    "    \"８\",\n",
    "    \"９\",\n",
    "    \"＜\",\n",
    "    \"＝\",\n",
    "    \"＞\",\n",
    "    \"＠\",\n",
    "    \"［\",\n",
    "    \"＼\",\n",
    "    \"］\",\n",
    "    \"＿\",\n",
    "    \"｀\",\n",
    "    \"ａ\",\n",
    "    \"ｂ\",\n",
    "    \"ｃ\",\n",
    "    \"ｄ\",\n",
    "    \"ｅ\",\n",
    "    \"ｆ\",\n",
    "    \"ｇ\",\n",
    "    \"ｈ\",\n",
    "    \"ｉ\",\n",
    "    \"ｊ\",\n",
    "    \"ｋ\",\n",
    "    \"ｌ\",\n",
    "    \"ｍ\",\n",
    "    \"ｎ\",\n",
    "    \"ｏ\",\n",
    "    \"ｐ\",\n",
    "    \"ｑ\",\n",
    "    \"ｒ\",\n",
    "    \"ｓ\",\n",
    "    \"ｔ\",\n",
    "    \"ｕ\",\n",
    "    \"ｖ\",\n",
    "    \"ｗ\",\n",
    "    \"ｘ\",\n",
    "    \"ｙ\",\n",
    "    \"ｚ\",\n",
    "    \"｛\",\n",
    "    \"｝\",\n",
    "    \"～\",\n",
    "    \"￥\",\n",
    "    \"a\",\n",
    "    \"b\",\n",
    "    \"c\",\n",
    "    \"d\",\n",
    "    \"e\",\n",
    "    \"f\",\n",
    "    \"g\",\n",
    "    \"h\",\n",
    "    \"i\",\n",
    "    \"j\",\n",
    "    \"k\",\n",
    "    \"l\",\n",
    "    \"m\",\n",
    "    \"n\",\n",
    "    \"o\",\n",
    "    \"p\",\n",
    "    \"q\",\n",
    "    \"r\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"u\",\n",
    "    \"v\",\n",
    "    \"w\",\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    \"z\",\n",
    "    \"《\",\n",
    "    \"》\",\n",
    "    \"〔\",\n",
    "    \"〕\",\n",
    "    \"【\",\n",
    "    \"】\",\n",
    "    \"A\",\n",
    "    \"B\",\n",
    "    \"C\",\n",
    "    \"D\",\n",
    "    \"E\",\n",
    "    \"F\",\n",
    "    \"G\",\n",
    "    \"H\",\n",
    "    \"I\",\n",
    "    \"J\",\n",
    "    \"K\",\n",
    "    \"L\",\n",
    "    \"M\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"P\",\n",
    "    \"Q\",\n",
    "    \"R\",\n",
    "    \"S\",\n",
    "    \"T\",\n",
    "    \"U\",\n",
    "    \"V\",\n",
    "    \"Ｗ\",\n",
    "    \"Ｘ\",\n",
    "    \"Ｙ\",\n",
    "    \"Ｚ\",\n",
    "    \"＾\",\n",
    "    \"｜\",\n",
    "    \"￠\",\n",
    "    \"￡\",\n",
    "    \"~\",\n",
    "    \"¶\",\n",
    "    \"W\",\n",
    "    \"Y\",\n",
    "    \"Z\",\n",
    "    \"^\",\n",
    "    \"|\",\n",
    "    \"丨\"\n",
    "\n",
    "]\n",
    "\n",
    "def clean(content, remove=REMOVE, remove_whitespace=True, simplified=False):\n",
    "    # These two lines are useful for Chinese texts where there was no whitespace or punctuation\n",
    "    # in the original documents\n",
    "    if remove_whitespace:\n",
    "        content = re.sub(\"\\s+\", \"\", content)\n",
    "        content = re.sub(\"\\n+\", \"\", content)\n",
    "    content = content.translate(str.maketrans(\"\", \"\", \"\".join(remove)))\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0bf7925-cba9-47a9-ac21-5430ce433f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_folder = '/Users/lola/Manning_DATA490/texts'\n",
    "output_folder = '/Users/lola/Manning_DATA490/cleaned_texts'\n",
    "\n",
    "files_with_decoding_errors = []\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    # Skip files starting with a dot (hidden files and .DS_store\n",
    "    if file.startswith('.'):\n",
    "        continue\n",
    "\n",
    "    input_filepath = os.path.join(input_folder, file)\n",
    "    output_filepath = os.path.join(output_folder, file)  # move cleaned file to 'cleaned_texts' folder\n",
    "\n",
    "\n",
    "    with open(input_filepath, 'r', encoding = 'utf-8', errors = 'replace') as file:\n",
    "        content = file.read()\n",
    "\n",
    "        chinese_chars_only = clean(content)\n",
    "              \n",
    "    with open(output_filepath, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(chinese_chars_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b747412-440b-482f-a5dd-518f817eeb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32478\n"
     ]
    }
   ],
   "source": [
    "folder_path = '/Users/lola/Manning_DATA490/cleaned_texts'\n",
    "\n",
    "# Get the list of files in the folder\n",
    "files_list = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Initialize lists to store file names and lengths\n",
    "file_names = []\n",
    "file_lengths = []\n",
    "\n",
    "# Iterate through each file\n",
    "for file_name in files_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Get the length of the file\n",
    "    file_size = os.path.getsize(file_path)\n",
    "\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Append modified file name and length to respective lists\n",
    "    file_names.append(file_name_without_extension)\n",
    "    file_lengths.append(file_size)\n",
    "\n",
    "# Create a DataFrame from the lists\n",
    "file_data = {'id': file_names, 'length': file_lengths}\n",
    "file_df = pd.DataFrame(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06037531-307d-49e7-9492-9853afd30876",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(corpus, file_df, on='id', how='inner') #merge corpus df with the new file id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5a531-b098-4b77-a478-c0f2267fea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['id', 'title','genre','author','era','length'] #select columns wanted from df\n",
    "selected_df = merged_df[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c7ff8-8fa2-4be1-963b-63ad5734b404",
   "metadata": {},
   "source": [
    "Add Tokenization Ratios to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa79f6c4-e590-44b7-b575-3155e11b124a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#n-gram tokenizer without spaces\n",
    "def n_gram_tokenizer(text, n = 1):\n",
    "    return [text[i:i+n] for i in range(len(text) - (n - 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52d73202-ab71-4789-9814-9714564629ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get ratio\n",
    "def get_ratio(result):\n",
    "    return len(set(result))/len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c523f1-98f7-41bc-b296-08db8390a4d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#add spaces\n",
    "def add_spaces(result):\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9586efba-c92d-454d-bd26-7d8b9e55f256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#main function\n",
    "def ratio(text, n = 1):\n",
    "    result = n_gram_tokenizer(text, n)\n",
    "    return get_ratio(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311ca1d3-e9eb-4789-9f74-e8bbdb76d585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#main function for jieba\n",
    "def ratio_jieba(text):\n",
    "    result = list(jieba.cut(text))  # Tokenize the text using jieba.cut\n",
    "    return get_ratio(result)  # Calculate the ratio using the get_ratio function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16660d64-cfb2-4b34-8e82-928ca1c4d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 1 gram to df\n",
    "folder_path = '/Users/lola/Manning_DATA490/cleaned_texts'\n",
    "\n",
    "ids = []\n",
    "ratios = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Apply the function ratio() to the content of each file\n",
    "    result = ratio(file_content)\n",
    "    \n",
    "    # Extract the id from the file_name (assuming the file_name is the id)\n",
    "    file_id = file_name.split('.')[0]\n",
    "    #try:\n",
    "        #file_id = int(file_name.split('.')[0])  # Assuming the file name is in the format \"id.txt\"\n",
    "    #except ValueError:\n",
    "        #pass  # Skip files that do not contain numeric identifiers\n",
    "    \n",
    "    ids.append(file_id)\n",
    "    ratios.append(result)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df1 = pd.DataFrame({'id': ids, '1 Gram Ratio': ratios})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558bdf06-ee81-4e07-9646-5678d0b18b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1 = pd.merge(selected_df, df1, on='id', how='inner') #merge with main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4937f-ad1f-408d-a9da-1982806ac5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 2 gram to df\n",
    "folder_path = '/Users/lola/Manning_DATA490/cleaned_texts'\n",
    "\n",
    "ids = []\n",
    "ratios = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Apply the function ratio() to the content of each file\n",
    "    result = ratio(file_content,2)\n",
    "    \n",
    "    # Extract the id from the file_name (assuming the file_name is the id)\n",
    "    file_id = None\n",
    "    try:\n",
    "        file_id = int(file_name.split('.')[0])  # Assuming the file name is in the format \"id.txt\"\n",
    "    except ValueError:\n",
    "        pass  # Skip files that do not contain numeric identifiers\n",
    "    \n",
    "    ids.append(file_id)\n",
    "    ratios.append(result)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df2 = pd.DataFrame({'id': ids, '2 Gram Ratio': ratios}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db48d7-e92f-4916-912e-e61d401e216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2 = pd.merge(merged_1, df2, on='id', how='inner') #merge with main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfff0030-ea95-4acc-b0cd-eeabf4ac1448",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/Users/lola/Manning_DATA490/cleaned_texts/.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path):\n\u001b[1;32m      8\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file_name)\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     11\u001b[0m         file_content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Apply the function ratio() to the content of each file\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/Users/lola/Manning_DATA490/cleaned_texts/.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "#add jieba to df\n",
    "folder_path = '/Users/lola/Manning_DATA490/cleaned_texts'\n",
    "\n",
    "ids = []\n",
    "ratios = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Apply the function ratio() to the content of each file\n",
    "    result = ratio_jieba(file_content)\n",
    "    \n",
    "    # Extract the id from the file_name (assuming the file_name is the id)\n",
    "    file_id = None\n",
    "    try:\n",
    "        file_id = int(file_name.split('.')[0])  # Assuming the file name is in the format \"id.txt\"\n",
    "    except ValueError:\n",
    "        pass  # Skip files that do not contain numeric identifiers\n",
    "    \n",
    "    ids.append(file_id)\n",
    "    ratios.append(result)\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "dfjieba = pd.DataFrame({'id': ids, 'Jieba Ratio': ratios})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c4444-fc9e-4e86-b053-82c32e888867",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(merged_2, dfjieba, on='id', how='inner') #merge with main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efeac4-efd0-4d91-806d-4e0500da0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4a222-76d3-4ec4-8d53-f8e63a2bbb81",
   "metadata": {},
   "source": [
    "Download 'genres' and 'texts' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf50d1-2dd8-4adc-9162-6f946f1a8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/lola/Manning_DATA490/cleaned_texts' #path to folder of cleaned texts\n",
    "\n",
    "genres = []\n",
    "texts = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    if file_name.startswith('.'): #skip file if starts with '.'\n",
    "        continue\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        \n",
    "    genre_index = file_name.split('.')[0]  # Extract genre index from file name\n",
    "    \n",
    "    if len(genre_index) > 0:\n",
    "        genre_col = classify_df.loc[classify_df['id'] == str(genre_index)]\n",
    "        if not genre_col.empty:\n",
    "            genre = genre_col['genre'].iloc[0]  # Get the genre value from DataFrame\n",
    "        else:\n",
    "            print(f\"Genre not found for index {genre_index}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(\"Genre index not found\")\n",
    "        continue\n",
    "     \n",
    "    # Apply preprocessing to individual document\n",
    "    file_content = pre_process(file_content)\n",
    "    \n",
    "    genres.append(genre)\n",
    "    texts.append(file_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
